# Interconnected network of CPS devices and delay measurement of the network

Abstract— A testbed was built that included devices such as a  Programmable Logic Controller (PLC), two Raspberry PI, camera, conveyor belt, robotic arm, and high-performance laptop for edge computing. Then, like industry standards, an  assembly line system was developed. The object in the conveyor  belt is first detected by the Raspberry Pi with a camera. Object  detection was done by the Yolo algorithm. The object detected  signals were sent to the PLC, which controls the conveyor belt  and sends commands to the robotic arm via Raspberry Pi.  Based on the detected object type, the robotic arm can perform  a specific task. The network switch connects all these devices,  and the communication protocol is TCP/IP. Signals passed  through various nodes on their way from object detection to  robotic arm motion. When signals are computed and  transmitted from one device to another, computational and  transfer delays are introduced. As a result, the system  experiences lag after commands are send. Because there are  multiple devices in our testbed, the delay will be greater. The  delay in the various nodes were thoroughly investigated and  measured. The solutions proposed for the delay have led to  substantial improvements. When compared to object detection  using a Raspberry Pi, edge computing reduces object detection  time by around 7 times. The combination of edge computing  with a high-performance hardware device result in a significant  decrease of total network delay. 

Keywords— Programmable Logic Controller (PLC), Robotic  Arm, Network Delay, Raspberry Pi (PI), Python,  Ladder Programming, Cyber-Physical System  (CPS), YOLO, Edge Computing

## Introduction

According to Lee and Seshia, the term Cyber-Physical System was coined by Helen Gill around 2006, at the National Science Foundation (NSF) in the U.S., to refer to the integration of computation with physical processes [1]. Often, it also has a communicating or networked aspect. The interconnected system of different physical and computational components that provides the foundation of engineering application, and base of emerging smart services refer to Cyber-Physical Systems. Cyber-Physical System (CPS) innovation and application are emerging in real life word such as Embedded Systems, Control Theory, and Mechatronics. Reactive computation, concurrency, feedback control of the physical world, real-time computation, and safety-critical applications are some of the features of CPS. Cleaning robots, smart heating, medical instruments, industrial systems, electric bikes, and smart grids are just a few examples of real world CPS applications. The use of CPS in health-care applications such as image-guided surgery, robotic surgery, and brain-machine interfaces is growing. In this era of Industry 4.0, cps develops smart industry capabilities and aids in the development of the industrial internet of things. CPS uses modern control systems, a variety of hardware and software, and the Internet of Things (IoT) to create new ways of producing, creating value, and optimizing in real-time. The CPS can be connected to the internet, allowing for cloud computing, smart monitoring, and data management. CPS is critical to the fourth industrial revolution's organization and improvement. The Industrial control system (ICS) contains a wide range of CPS applications. Industrial processes are automated using a variety of devices, systems, controls, and networks. The most common ICS are Supervisory Control and Data Acquisition (SCADA) systems and Distributed Control Systems (DCS). Within the same geographic region, a distributed control system (DCS) is utilized to control production systems. It typically consists of a computer that communicates with control devices located throughout the plant or process, such as machine or process controllers and PLCs, through a bus or directly, and displays the data gathered. For command and monitoring, DCS systems typically include a hierarchy of controllers located throughout a plant and connected by a communications network, whereas SCADAs have centralized control. DCS components are frequently seen in SCADA systems. DCS control system are organized into five subsystems: process interface, process control, process operations, applications engines, and communication subsystems. The DCS is more process oriented whereas SCADS is data oriented [2]. The simple architecture of the DCS is expressed in figure 1. The DCS system consists of multiple controlling elements and reliability of the system increases.


![DCS controlling different parts](https://user-images.githubusercontent.com/48818645/209208406-0855b5b3-500b-43e5-9cc6-b713788c0030.PNG)

Figure 1: DCS controlling multiple devices with PLC 


In the industry, the use of robots and robotic arms is increasing. There is automation everywhere. A similar assembly line is created in this experiment using a conveyor belt and a robotic arm. “Machine vision systems (MVS) are based on capturing an image (typically via camera), extracting a series of data from that image, analyzing it, and once evaluated, deciding accordingly [3]. MVP is critical in the development of automated systems. According to a report published by the German industry association VDMA, the machine vision industry grew by 2.6 billion euros in 2017, with the automotive industry accounting for a large portion of that growth [4]. The production industry is focused on robots and machine vision for, which is critical to the growth of Industry V4.0. In real-time machine operation, even a millisecond delay is significant. The object detection algorithm used by the MVS has been optimized to speed up the process. To reduce computational time and memory, a variety of new machine learning and neural network techniques have been optimized for image and video analyses. Deep neural networks have improved their performance to process visual data over time [5]. They have been established as a key player in computer vision applications. Object vision is used in a variety of fields, including autonomous driving, surveying, and health care. Various algorithms were developed, including Fast R-CNN, Faster R-CNN, Single Shot Detector (SSD), Spatial Pyramid Pooling (SPP-net), and YOLO (You Only Look Once) [6]. The state of the art in object detection is YOLO. Yolo is used in this study to detect objects on the conveyor belt. The rapid development 3D object detection and next-generation sensor will help to grow the automation industry. Various components were connected to form a network in this experiment. With the help of the Yolo algorithm, the Pi camera is used to capture video of the conveyor system and detect object. The object detection signal is then sent to a PLC, which controls the conveyor belt as well as a second Pi with a robotic arm. The Raspberry Pi collects data from the PLC and uses it to control the robotic arm. The Raspberry Pi and robotic arm are both programmed in Python. Ladder programming is used to program the PLC. The experiment set up is explained with the help of figure 4. Signals passed through various nodes on their way from object detection to robotic arm motion. When signals are computed and transmitted from one device to another, computational and transfer delays are introduced. As a result, the system experienced some lag after commands were sent. Because there are multiple devices in our testbed, the delay will be greater. The delay in the various nodes were thoroughly investigated and measured.

## Proposed System
In this section, the brief explanation regarding the hardware, software, and challenges are discussed. In this testbed, the PLC serves as the central system. It acts as a communication bridge between two Raspberry PI’s and controls the conveyor belt. A 24V dc motor on the conveyor belt is directly connected to the PLC. The PLC memory is updated with the object class when the object is detected in a moving conveyor belt. The conveyor belt is directly connected to the PLC's output pins and is controlled using ladder logic. The conveyor belt gets stopped when an object is detected within the camera frame. The PI controlling the robotic arm receives the object's information from the PLC memory and instructs the robotic arm to drag the object away from the conveyor belt.

### A. Hardware

One PI controls the camera, while the other controls the  robotic arm. The PLC functions as a central station, receiving  signals from one PI and sending them to another. Let's go over  each component in the testbed and their functions. Only the  physical operation is defined in this section and software  which operates hardware will be discussed later. The functions  of each device in the testbed are listed in table. 

![device with the functions](https://user-images.githubusercontent.com/48818645/209210582-75fce2db-d1ab-494f-915b-598f12b31868.PNG)

The conveyor belt was improved, and a 24v 5RPM motor was installed. The motor can be controlled directly by the PLC. The testbed's sequential operation is described below.
1. The PI1 camera continuously monitors the object on the conveyor belt as it moves. The PLC is used to control the conveyor belt. The PI camera will be at some height above the conveyor belt. 
2. If the camera detects our target objects, PI1 sends commands to the PLC. 
3. The PLC receives information about the object's class and location. The PLC sends the same data to the PI2. The PLC then instructs the conveyor belt to come to a halt. 
4. The PLC sends signals to the PI2 with robotic arm about the object's class and location. The arm's servo motors are then given commands to perform a specific task for that object. 
5. This process continues. 

Signals travel from various nodes and devices to detect objects and move robotic arms. The signals are computed at each device, which increases the signal delay. We're looking for a delay in signal transmission between nodes in this experiment.


### B. Software

Hardware cannot run standalone. The backbone that drives  the hardware is software. Python is used to program the  Raspberry Pi and robotic arm. Ladder programming is used in  PLCs. The figure 3 explains about the modules and software  used. 

![software n it's function](https://user-images.githubusercontent.com/48818645/209211856-2d45f788-1427-448f-9ac3-000c074f36af.PNG)

The video is captured by the camera, which is then processed by the Yolov5 algorithm (via PI1) to detect the object. The Raspberry Pi's object detection time is quite long. Using the snap7 python library, the object's class is written into the PLC's data base memory. After reading the PLC's memory about the object's location and class, PI2 controls the robotic arm.

![block diagram](https://user-images.githubusercontent.com/48818645/209212790-97291674-bcb6-4d50-87ca-2785cdc6506f.PNG)



